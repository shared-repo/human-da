{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tf_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = \\\n",
    "    tf_keras.utils.text_dataset_from_directory(\"data-files/aclImdb/train\", batch_size=32)\n",
    "test_dataset = \\\n",
    "    tf_keras.utils.text_dataset_from_directory(\"data-files/aclImdb/test\", batch_size=32)\n",
    "# review_only_dataset = train_dataset.map(lambda X, y: X)\n",
    "review_only_dataset = train_dataset.map(lambda review, label: review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32,) (32,)\n",
      "tf.Tensor(b'COME ON!!! They did that on purpose!! Two of my current faves on TV (Meloni from \"Oz\" and \"L and O-SVU\" and Janel from \"West Wing\") hook up for a nice little sleeper/character study. Plot\\'s nothing fancy, but the acting is right on the mark. Tim Busfield shows up for some neat bits. Worth a look.', shape=(), dtype=string)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_dataset:\n",
    "    print(X.shape, y.shape)\n",
    "    print(X[0])\n",
    "    print(y[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\human\\.conda\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\human\\.conda\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 문장(단어 집합) -> 숫자 집합 : encoding\n",
    "text_vectorizer = \\\n",
    "    tf_keras.layers.TextVectorization(max_tokens=20000, # 사전 크기, 총 단어 갯수\n",
    "                                      output_mode=\"int\",\n",
    "                                      output_sequence_length=300) # 한 문장의 단어 갯수 \n",
    "\n",
    "text_vectorizer.adapt(review_only_dataset) # 변환기에 단어 사전 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 300)\n",
      "tf.Tensor(\n",
      "[[ 414   10  118 ...   13   11   18]\n",
      " [  32   10   26 ...    0    0    0]\n",
      " [   4 1603   64 ...    0    0    0]\n",
      " ...\n",
      " [  48   24  106 ...    0    0    0]\n",
      " [   9    7  264 ...    0    0    0]\n",
      " [ 156   11   91 ...  109   11  139]], shape=(32, 300), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# (문장 -> 숫자 리스트) 변환기 테스트\n",
    "for X, y in train_dataset:\n",
    "    d = text_vectorizer(X) # 변환 실행 [ X: (32, 1) -> X: (32, 300)]\n",
    "    print(d.shape)\n",
    "    print(d)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i', 'this', 'that', 'br', 'was', 'as', 'for', 'with', 'movie', 'but']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 사전 확인\n",
    "dictionary = text_vectorizer.get_vocabulary()\n",
    "print( len(dictionary) )\n",
    "dictionary[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 414   10  118  142   29    5    2  164   83 6649    6    1   11]\n",
      "yes i know im one of the few people longing to [UNK] this movie into the dust of [UNK] let me me tell you why i feel this way in [UNK] it been [UNK] as a zombie film or the [UNK] might have enjoyed itbut right [UNK] totally [UNK] br [UNK] im not sure whats to spoil lets start with the first huge flaw if i did not know that the movie is called darkness the vampire version and had i not seen some sequences where some individuals seem to be sucking blood i would not have seen the connection with vampires i mean [UNK] give me a breakbr br second bad point whats with the metal it appears that all young people but mainly those socalled vampires are into various kinds of [UNK] mainly by their shirts dont get me wrong ive been into the more extreme forms of music for almost 15 years but nobody s going to scare me by showing me some ridiculous teenagers in iron maiden of all bands tshirts running [UNK] to be vampires pathetic is the only only word that i could use herebr br third weakness the actors wait a minute what actors you mean the directors wooden friends words would be a waste herebr br yes alright the movie is very gory but what difference does that make it would have been a strong point and something to enjoy if the [UNK] director had not chosen to create an artificial vampire topic in this movie i wanted to see [UNK] was treated to some stupid looking kids i would have loved to use my baseball bat on the filmmakers should simply have [UNK] the movie saying cheap bgrade horror with no plot but a lot of gore br br this movie "
     ]
    }
   ],
   "source": [
    "# 숫자로 인코딩된 문장을 원래 문장으로 복원\n",
    "print(d[0][:13].numpy())\n",
    "for t in d[0]:\n",
    "    if t != 0:\n",
    "        print(dictionary[t], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding 모델 만들기 : 단어(토큰을 벡터로 만드는 모델)\n",
    "\n",
    "input = tf_keras.layers.Input(shape=(None,))\n",
    "output = tf_keras.layers.Embedding(input_dim=20000, output_dim=100)(input)\n",
    "\n",
    "embedding_model = tf_keras.models.Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review in review_only_dataset:\n",
    "    # print( review )\n",
    "    vectorized_review = text_vectorizer(review)             # 단어 1개 -> 숫자 1개\n",
    "    embedded_review = embedding_model(vectorized_review)    # 숫자 1개 -> 숫자 100개\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([32, 300]), TensorShape([32, 300, 100]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_review.shape, embedded_review.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터의 모든 문자열(리뷰)을 숫자로 변경\n",
    "vectorized_train_dataset = \\\n",
    "    train_dataset.map( lambda review, label: (text_vectorizer(review), label) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  45   23  731 ...    0    0    0]\n",
      " [ 150    9   59 ...    0    0    0]\n",
      " [  10   41  284 ...    0    0    0]\n",
      " ...\n",
      " [  22  593    4 ...    0    0    0]\n",
      " [  10  604  369 ...    4  738    5]\n",
      " [   2  838 3632 ...    0    0    0]], shape=(32, 300), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# 변경 확인\n",
    "for X, y in vectorized_train_dataset:\n",
    "    print(X)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_4 (Embedding)     (None, None, 100)         2000000   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 16)                7488      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2007505 (7.66 MB)\n",
      "Trainable params: 2007505 (7.66 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 구조 설계 : 텍스트 데이터 처리를 위한 순환신경망 모델\n",
    "\n",
    "input = tf_keras.layers.Input(shape=(None,))\n",
    "x = tf_keras.layers.Embedding(input_dim=20000, output_dim=100)(input) # None, 300, 100\n",
    "x = tf_keras.layers.LSTM(units=16)(x)\n",
    "output = tf_keras.layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = tf_keras.models.Model(input, output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 설계\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 72s 90ms/step - loss: 0.6857 - accuracy: 0.5313\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 72s 92ms/step - loss: 0.6722 - accuracy: 0.5724\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 69s 89ms/step - loss: 0.6364 - accuracy: 0.5813\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 70s 89ms/step - loss: 0.5910 - accuracy: 0.5987\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 72s 91ms/step - loss: 0.5764 - accuracy: 0.6073\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 71s 90ms/step - loss: 0.5636 - accuracy: 0.6113\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 76s 97ms/step - loss: 0.5422 - accuracy: 0.6184\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 79s 101ms/step - loss: 0.5396 - accuracy: 0.6165\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 74s 95ms/step - loss: 0.4781 - accuracy: 0.7566\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 77s 98ms/step - loss: 0.4814 - accuracy: 0.7650\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "\n",
    "history = model.fit(vectorized_train_dataset, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human-dl-env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
