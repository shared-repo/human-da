{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5O2tKbiMKvpP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as tf_keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 준비\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = tf_keras.datasets.boston_housing.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1zgaiyHLqcn",
        "outputId": "ae5cd23e-a533-4982-be41-f99a68a9bb80"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "\u001b[1m57026/57026\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [ feature names (마지막은  target name) ]\n",
        "# CRIM - per capita crime rate by town\n",
        "# ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "# INDUS - proportion of non-retail business acres per town.\n",
        "# CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
        "# NOX - nitric oxides concentration (parts per 10 million)\n",
        "# RM - average number of rooms per dwelling\n",
        "# AGE - proportion of owner-occupied units built prior to 1940\n",
        "# DIS - weighted distances to five Boston employment centres\n",
        "# RAD - index of accessibility to radial highways\n",
        "# TAX - full-value property-tax rate per $10,000\n",
        "# PTRATIO - pupil-teacher ratio by town\n",
        "# B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
        "# LSTAT - % lower status of the population\n",
        "# MEDV - Median value of owner-occupied homes in $1000's\n",
        "\n",
        "print( X_train.shape, y_train.shape )\n",
        "print( X_train[0] )\n",
        "print( y_train[:10] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WSwUY3rL8e3",
        "outputId": "63e99301-7e2f-4917-f564-21fc3d29b9aa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(404, 13) (404,)\n",
            "[  1.23247   0.        8.14      0.        0.538     6.142    91.7\n",
            "   3.9769    4.      307.       21.      396.9      18.72   ]\n",
            "[15.2 42.3 50.  21.1 17.7 18.5 11.3 15.6 15.6 14.4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 회귀 모델 층 설계\n",
        "\n",
        "# model = tf_keras.Sequential([\n",
        "#     # tf_keras.layers.Dense( 64, input_shape=[13] ), #  입력을 은닉층의 속성으로 설정\n",
        "#     tf_keras.layers.Input(shape=(13, )),\n",
        "#     tf_keras.layers.Dense(64, activation=\"relu\"),\n",
        "#     tf_keras.layers.Dense(32, activation='relu'),\n",
        "#     tf_keras.layers.Dense(1) # 출력층 : 회귀의 출력층 유닛갯수는 1개, 출력함수는 항등함수(지정하지 않음)\n",
        "# ])\n",
        "\n",
        "model = tf_keras.Sequential()\n",
        "model.add(tf_keras.layers.Input(shape=(13, )))\n",
        "# model.add(tf_keras.layers.Dense(64, activation=\"relu\"))\n",
        "model.add(tf_keras.layers.Dense(64, activation=tf_keras.layers.ReLU())) # 클래스 사용 : 세부사항 정의 가능\n",
        "model.add(tf_keras.layers.Dense(32, activation='relu')) # 문자열 사용 : 기본 값 적용\n",
        "model.add(tf_keras.layers.Dense(1)) # 출력층 : 회귀의 출력층 유닛갯수는 1개, 출력함수는 항등함수(지정하지 않음)"
      ],
      "metadata": {
        "id": "Tyl3_N4gNlUH"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 회귀 모델 학습 설계 : 손실 및 가중치 업데이트 방법 결정\n",
        "\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['mse', 'mae'])\n"
      ],
      "metadata": {
        "id": "xz14DFz_Pgdm"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "# 모델 훈련 (학습)\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=32, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKoXgOzwQDd2",
        "outputId": "f07bdf00-4b6f-4ea0-b142-c96405a2a5bb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6714.7651 - mae: 69.7067 - mse: 6714.7651   \n",
            "Epoch 2/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1283.7128 - mae: 32.3161 - mse: 1283.7128 \n",
            "Epoch 3/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 327.2830 - mae: 15.0070 - mse: 327.2830 \n",
            "Epoch 4/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 161.4523 - mae: 9.5517 - mse: 161.4523 \n",
            "Epoch 5/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 108.4180 - mae: 8.2851 - mse: 108.4180\n",
            "Epoch 6/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 106.1697 - mae: 8.0733 - mse: 106.1697\n",
            "Epoch 7/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 101.1840 - mae: 7.5984 - mse: 101.1840  \n",
            "Epoch 8/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 78.8146 - mae: 6.5490 - mse: 78.8146 \n",
            "Epoch 9/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68.2073 - mae: 6.2581 - mse: 68.2073 \n",
            "Epoch 10/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73.3432 - mae: 6.3317 - mse: 73.3432   \n",
            "Epoch 11/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70.0259 - mae: 6.2661 - mse: 70.0259 \n",
            "Epoch 12/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.9934 - mae: 5.6111 - mse: 64.9934 \n",
            "Epoch 13/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67.0011 - mae: 5.7682 - mse: 67.0011  \n",
            "Epoch 14/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69.3742 - mae: 5.9200 - mse: 69.3742   \n",
            "Epoch 15/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.9229 - mae: 5.5915 - mse: 58.9229 \n",
            "Epoch 16/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.4532 - mae: 5.4978 - mse: 63.4532 \n",
            "Epoch 17/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68.4050 - mae: 5.9242 - mse: 68.4050 \n",
            "Epoch 18/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67.8644 - mae: 5.6801 - mse: 67.8644 \n",
            "Epoch 19/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.9031 - mae: 4.9782 - mse: 55.9031 \n",
            "Epoch 20/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66.6039 - mae: 5.7753 - mse: 66.6039 \n",
            "Epoch 21/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48.5487 - mae: 4.8852 - mse: 48.5487  \n",
            "Epoch 22/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.3803 - mae: 5.7515 - mse: 63.3803 \n",
            "Epoch 23/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.2902 - mae: 5.3895 - mse: 59.2902 \n",
            "Epoch 24/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.3056 - mae: 5.5721 - mse: 63.3056 \n",
            "Epoch 25/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50.9242 - mae: 4.7930 - mse: 50.9242 \n",
            "Epoch 26/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.5131 - mae: 5.4659 - mse: 58.5131 \n",
            "Epoch 27/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 49.8913 - mae: 4.9817 - mse: 49.8913 \n",
            "Epoch 28/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 47.2222 - mae: 4.6348 - mse: 47.2222 \n",
            "Epoch 29/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.6641 - mae: 5.3230 - mse: 54.6641 \n",
            "Epoch 30/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.9284 - mae: 5.0891 - mse: 57.9284 \n",
            "Epoch 31/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50.3835 - mae: 4.7085 - mse: 50.3835 \n",
            "Epoch 32/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 43.2551 - mae: 4.4377 - mse: 43.2551 \n",
            "Epoch 33/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.5511 - mae: 5.5044 - mse: 59.5511 \n",
            "Epoch 34/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.5036 - mae: 5.1475 - mse: 53.5036 \n",
            "Epoch 35/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.8343 - mae: 5.0114 - mse: 56.8343 \n",
            "Epoch 36/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 41.8576 - mae: 4.4896 - mse: 41.8576  \n",
            "Epoch 37/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 42.8911 - mae: 4.3831 - mse: 42.8911  \n",
            "Epoch 38/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 50.8345 - mae: 4.7916 - mse: 50.8345 \n",
            "Epoch 39/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 42.8883 - mae: 4.7484 - mse: 42.8883 \n",
            "Epoch 40/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 44.3266 - mae: 4.4475 - mse: 44.3266 \n",
            "Epoch 41/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 41.4029 - mae: 4.4259 - mse: 41.4029 \n",
            "Epoch 42/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 41.1634 - mae: 4.2237 - mse: 41.1634 \n",
            "Epoch 43/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 39.8658 - mae: 4.5032 - mse: 39.8658 \n",
            "Epoch 44/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 46.1207 - mae: 4.7886 - mse: 46.1207  \n",
            "Epoch 45/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 38.6545 - mae: 4.1222 - mse: 38.6545  \n",
            "Epoch 46/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.7332 - mae: 4.5616 - mse: 40.7332 \n",
            "Epoch 47/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 42.5760 - mae: 4.3869 - mse: 42.5760 \n",
            "Epoch 48/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.7310 - mae: 4.0969 - mse: 31.7310 \n",
            "Epoch 49/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.9615 - mae: 4.6018 - mse: 40.9615 \n",
            "Epoch 50/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.9260 - mae: 4.2647 - mse: 34.9260 \n",
            "Epoch 51/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.6519 - mae: 4.0814 - mse: 34.6519 \n",
            "Epoch 52/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.8454 - mae: 4.1320 - mse: 35.8454  \n",
            "Epoch 53/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.0707 - mae: 4.0819 - mse: 34.0707 \n",
            "Epoch 54/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 37.1590 - mae: 4.1654 - mse: 37.1590 \n",
            "Epoch 55/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 38.1879 - mae: 4.2401 - mse: 38.1879 \n",
            "Epoch 56/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.4580 - mae: 4.1067 - mse: 38.4580 \n",
            "Epoch 57/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 33.4645 - mae: 4.0936 - mse: 33.4645 \n",
            "Epoch 58/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.2732 - mae: 4.4377 - mse: 38.2732 \n",
            "Epoch 59/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 39.3114 - mae: 4.5096 - mse: 39.3114 \n",
            "Epoch 60/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.4632 - mae: 3.8284 - mse: 28.4632 \n",
            "Epoch 61/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 33.2917 - mae: 3.9957 - mse: 33.2917 \n",
            "Epoch 62/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32.1510 - mae: 4.0948 - mse: 32.1510 \n",
            "Epoch 63/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31.5037 - mae: 3.9365 - mse: 31.5037 \n",
            "Epoch 64/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 33.0627 - mae: 4.1697 - mse: 33.0627 \n",
            "Epoch 65/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37.3651 - mae: 4.2504 - mse: 37.3651 \n",
            "Epoch 66/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32.4191 - mae: 4.0332 - mse: 32.4191 \n",
            "Epoch 67/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 36.8465 - mae: 4.2733 - mse: 36.8465  \n",
            "Epoch 68/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 40.2073 - mae: 4.3747 - mse: 40.2073  \n",
            "Epoch 69/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.1552 - mae: 3.8427 - mse: 28.1552 \n",
            "Epoch 70/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34.0676 - mae: 4.0613 - mse: 34.0676 \n",
            "Epoch 71/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.5213 - mae: 4.2770 - mse: 38.5213 \n",
            "Epoch 72/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31.1953 - mae: 4.1507 - mse: 31.1953 \n",
            "Epoch 73/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 33.2453 - mae: 4.2736 - mse: 33.2453 \n",
            "Epoch 74/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.6105 - mae: 3.9145 - mse: 28.6105 \n",
            "Epoch 75/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 40.0612 - mae: 4.9631 - mse: 40.0612 \n",
            "Epoch 76/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 35.9127 - mae: 4.4613 - mse: 35.9127 \n",
            "Epoch 77/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30.6127 - mae: 3.9674 - mse: 30.6127 \n",
            "Epoch 78/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37.3754 - mae: 4.0251 - mse: 37.3754 \n",
            "Epoch 79/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.6422 - mae: 4.0212 - mse: 31.6422 \n",
            "Epoch 80/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32.7321 - mae: 4.0211 - mse: 32.7321 \n",
            "Epoch 81/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.1971 - mae: 3.7981 - mse: 28.1971  \n",
            "Epoch 82/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.9937 - mae: 3.5835 - mse: 26.9937 \n",
            "Epoch 83/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32.8180 - mae: 4.1379 - mse: 32.8180 \n",
            "Epoch 84/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.5927 - mae: 3.8072 - mse: 26.5927 \n",
            "Epoch 85/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.9460 - mae: 4.0378 - mse: 28.9460 \n",
            "Epoch 86/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34.2491 - mae: 4.3019 - mse: 34.2491 \n",
            "Epoch 87/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24.6639 - mae: 3.5742 - mse: 24.6639 \n",
            "Epoch 88/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30.7509 - mae: 4.0354 - mse: 30.7509 \n",
            "Epoch 89/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.8694 - mae: 3.8005 - mse: 28.8694 \n",
            "Epoch 90/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 33.4445 - mae: 4.0326 - mse: 33.4445 \n",
            "Epoch 91/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30.7210 - mae: 4.0146 - mse: 30.7210 \n",
            "Epoch 92/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32.6026 - mae: 4.2287 - mse: 32.6026 \n",
            "Epoch 93/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30.3012 - mae: 3.9921 - mse: 30.3012 \n",
            "Epoch 94/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 33.6167 - mae: 4.0622 - mse: 33.6167 \n",
            "Epoch 95/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.1978 - mae: 4.2157 - mse: 35.1978 \n",
            "Epoch 96/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 35.4191 - mae: 4.3858 - mse: 35.4191  \n",
            "Epoch 97/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30.4373 - mae: 4.1623 - mse: 30.4373 \n",
            "Epoch 98/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32.3890 - mae: 4.1838 - mse: 32.3890  \n",
            "Epoch 99/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.1958 - mae: 3.6502 - mse: 27.1958 \n",
            "Epoch 100/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34.0816 - mae: 4.1566 - mse: 34.0816 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7dc07dde31f0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "\n",
        "train_eval, test_eval = model.evaluate(X_train, y_train), model.evaluate(X_test, y_test)\n",
        "train_eval, test_eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPLmtOp2Qr-X",
        "outputId": "cedd1fa3-1d61-4f4f-ee4c-e348c57877c6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25.8586 - mae: 3.9144 - mse: 25.8586  \n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.5846 - mae: 4.1210 - mse: 31.5846 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([27.081775665283203, 27.081775665283203, 3.9010238647460938],\n",
              " [34.49043655395508, 34.49043655395508, 4.403345584869385])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( y_train.mean(), y_test.mean() )\n",
        "print( train_eval[2] / y_train.mean(), test_eval[2] / y_test.mean() )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLQta2c5RIJ2",
        "outputId": "77ff5c61-362f-4327-ced7-ff859bde433b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22.395049504950492 23.07843137254902\n",
            "0.17419134813181641 0.1907991714769232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 값 예측\n",
        "\n",
        "model.predict(X_test[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjtHHLjzR64H",
        "outputId": "853314f5-45bb-40b9-d650-58da697fc131"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9.588022],\n",
              "       [22.418661],\n",
              "       [24.308498],\n",
              "       [30.470167],\n",
              "       [26.42726 ],\n",
              "       [21.713404],\n",
              "       [29.563185],\n",
              "       [25.375946],\n",
              "       [20.223238],\n",
              "       [22.117834]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}